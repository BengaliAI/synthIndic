{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# imports\n",
    "#--------------------------------------\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from bnunicodenormalizer import Normalizer\n",
    "from indicparser.langs import bangla\n",
    "bangla.consonant_diacritics+=['ং','ঃ'] \n",
    "from indicparser import graphemeParser\n",
    "import random\n",
    "\n",
    "gp=graphemeParser(\"bangla\")\n",
    "bnorm=Normalizer()\n",
    "tqdm.pandas()\n",
    "#--------------------------------------\n",
    "# globals\n",
    "#--------------------------------------\n",
    "numbers                =    ['০', '১', '২', '৩', '৪', '৫', '৬', '৭', '৮', '৯']\n",
    "punctuations           =    ['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '।']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized Oscar Corpus\n",
    "* get unique graphemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs=[csv for csv in tqdm(glob(\"oscar/*.csv\"))]\n",
    "dfs=[pd.read_csv(csv) for csv in tqdm(csvs)]\n",
    "df=pd.concat(dfs)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"graphemes\"]=df.word.progress_apply(lambda x:gp.process(x))\n",
    "graphemes=df.graphemes.tolist()\n",
    "dict_graphemes=[]\n",
    "for _graphemes in tqdm(graphemes):\n",
    "    for grapheme in _graphemes:\n",
    "        if grapheme not in dict_graphemes:\n",
    "            dict_graphemes.append(grapheme)\n",
    "dict_graphemes=sorted([\"র‍্যা\"]+dict_graphemes)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphemes=[]\n",
    "for g in tqdm(dict_graphemes):\n",
    "    for cd in bangla.consonant_diacritics:\n",
    "        g=g.replace(cd,'')\n",
    "    if g not in graphemes+numbers:\n",
    "        graphemes.append(g)\n",
    "len(graphemes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random gen-funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_exec(poplutation=[0,1],weights=[0.5,0.5],match=0):\n",
    "    return random.choices(population=poplutation,weights=weights,k=1)[0]==match\n",
    "\n",
    "def create_words(graphemes,\n",
    "                min_len=1,\n",
    "                max_len=10,\n",
    "                mods=['ঁ', 'ং', 'ঃ'],\n",
    "                mod_weights=[0.3,0.7]):\n",
    "    \n",
    "    _graphemes = graphemes.copy()\n",
    "    random.shuffle(_graphemes)\n",
    "    words = [] \n",
    "    index = 0 \n",
    "    length = len(_graphemes) \n",
    "    while (index < length):\n",
    "        _len = random.randint(min_len,max_len)\n",
    "        word=_graphemes[index:index+_len]\n",
    "        if random_exec(weights=mod_weights):\n",
    "            wlen=len(word)\n",
    "            widx=random.randint(0,wlen-1)\n",
    "            word[widx]+=random.choice(mods) \n",
    "        words.append(\"\".join(word)) \n",
    "        index = index + _len\n",
    "    return words\n",
    "def create_numbers(numbers,\n",
    "                min_len=1,\n",
    "                max_len=10,\n",
    "                num_samples=100000):\n",
    "    \n",
    "    words = [] \n",
    "    for _ in range(num_samples):\n",
    "        _len = random.randint(min_len,max_len)\n",
    "        _word=[]\n",
    "        for _ in range(_len):_word.append(random.choice(numbers))\n",
    "        if random_exec():_word[random.randint(0,_len-1)]+=\".\"\n",
    "        words.append(\"\".join(_word))\n",
    "    return words\n",
    "\n",
    "def create_mixed_data(numbers,\n",
    "                    graphemes,\n",
    "                    punctuations,    \n",
    "                    num_samples=100000,\n",
    "                    lens= [1,2,3,4,5,6,7,8,9,10],\n",
    "                    weights= [0.05,0.05,0.1,0.15,0.15,0.15,0.15,0.1,0.05,0.05],\n",
    "                    comp_weights= [0.33,0.34,0.33]):\n",
    "    words=[]\n",
    "    for _ in tqdm(range(num_samples)):\n",
    "        len_word=random.choices(population=lens,weights=weights,k=1)[0]\n",
    "        _graphemes=[]\n",
    "        for _ in range(len_word):\n",
    "            _ctype=random.choices(population=[\"g\",\"n\",\"p\"],weights=comp_weights,k=1)[0]\n",
    "            if _ctype==\"g\":    \n",
    "                _graphemes.append(random.choice(graphemes))\n",
    "            elif _ctype==\"n\":    \n",
    "                _graphemes.append(random.choice(numbers))\n",
    "            else:\n",
    "                _graphemes.append(random.choice(punctuations))        \n",
    "        words.append(\"\".join(_graphemes))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_hf=1\n",
    "_sf=1\n",
    "_gf=1000\n",
    "df=pd.read_csv(\"hw.csv\")\n",
    "dfs=[df for _ in range(_hf)]\n",
    "df=pd.read_csv(\"sc.csv\")\n",
    "dfs+=[df for _ in range(_sf)]\n",
    "df=pd.concat(dfs,ignore_index=True)\n",
    "\n",
    "with open(\"bn_test.txt\",\"w+\") as f:\n",
    "    for idx in tqdm(range(len(df))):\n",
    "        word=df.iloc[idx,0]\n",
    "        f.write(f\"{word}\\n\")\n",
    "\n",
    "words=create_mixed_data(numbers,graphemes,punctuations)\n",
    "dfm=pd.DataFrame({\"word\":words})\n",
    "words=create_numbers(numbers)\n",
    "dfn=pd.DataFrame({\"word\":words})\n",
    "gwords=[]\n",
    "for i in tqdm(range(_gf)):\n",
    "    gwords+=create_words(graphemes)\n",
    "dfg=pd.DataFrame({\"word\":gwords})\n",
    "\n",
    "df=pd.concat([dfm,dfn,dfg],ignore_index=True)\n",
    "df=df.sample(frac=1)\n",
    "\n",
    "with open(\"bn_train.txt\",\"w+\") as f:\n",
    "    for idx in tqdm(range(len(df))):\n",
    "        word=df.iloc[idx,0]\n",
    "        f.write(f\"{word}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('bangla')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83cb0fe33a0a67f9f877ffb776c4b7cce63e124f7ba47fe6878fb868bcc96314"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
